import os
import pandas as pd
import pickle
import argparse
import importlib.util
import sys
from datetime import datetime

def load_config(config_file_path):
    """
    åŠ è½½é…ç½®æ–‡ä»¶å¹¶æå–æ‰€éœ€å‚æ•°
    
    Args:
        config_file_path (str): é…ç½®æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        
    Returns:
        dict: åŒ…å«æå–å‚æ•°çš„å­—å…¸
    """
    try:
        # åŠ¨æ€åŠ è½½é…ç½®æ–‡ä»¶
        spec = importlib.util.spec_from_file_location("config", config_file_path)
        config_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(config_module)
        
        # æå–å‚æ•°
        config_params = {}
        
        # æŸ¥æ‰¾é…ç½®ç±»å®ä¾‹
        config_instance = None
        
        # æŸ¥æ‰¾å¯èƒ½çš„é…ç½®ç±»å®ä¾‹åç§°
        possible_config_names = ['config', 'cfg', 'conf', 'settings']
        
        for attr_name in dir(config_module):
            if not attr_name.startswith('_'):
                attr_value = getattr(config_module, attr_name)
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç±»å®ä¾‹ä¸”ç±»ååŒ…å«config
                if hasattr(attr_value, '__class__') and 'config' in attr_value.__class__.__name__.lower():
                    config_instance = attr_value
                    print(f"ğŸ” æ‰¾åˆ°é…ç½®ç±»å®ä¾‹: {attr_name} (ç±»å‹: {attr_value.__class__.__name__})")
                    break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„é…ç½®ç±»å®ä¾‹ï¼Œå°è¯•æŸ¥æ‰¾Configç±»
        if config_instance is None:
            for attr_name in dir(config_module):
                if not attr_name.startswith('_') and 'config' in attr_name.lower():
                    attr_value = getattr(config_module, attr_name)
                    if hasattr(attr_value, '__class__') and hasattr(attr_value, 'dataset_path'):
                        config_instance = attr_value
                        print(f"ğŸ” æ‰¾åˆ°é…ç½®ç±»å®ä¾‹: {attr_name}")
                        break
        
        # å¦‚æœæ‰¾åˆ°äº†é…ç½®ç±»å®ä¾‹ï¼Œä»å®ä¾‹ä¸­æå–å‚æ•°
        if config_instance:
            print(f"ğŸ“‹ ä»é…ç½®ç±»å®ä¾‹ä¸­æå–å‚æ•°...")
            
            # è·å– dataset_path (å¯¹åº” output_dir)
            if hasattr(config_instance, 'dataset_path'):
                config_params['output_dir'] = config_instance.dataset_path
                print(f"   âœ… æ‰¾åˆ° dataset_path: {config_instance.dataset_path}")
            
            # è·å–æ—¶é—´èŒƒå›´å‚æ•°
            # train_end ä» train_time_range æå–ç»“æŸæ—¶é—´
            if hasattr(config_instance, 'train_time_range'):
                train_range = config_instance.train_time_range
                if isinstance(train_range, (list, tuple)) and len(train_range) >= 2:
                    config_params['train_end'] = train_range[1]
                    print(f"   âœ… æ‰¾åˆ° train_time_range: {train_range} â†’ train_end: {train_range[1]}")
            
            # val_end ä» val_time_range æå–ç»“æŸæ—¶é—´
            if hasattr(config_instance, 'val_time_range'):
                val_range = config_instance.val_time_range
                if isinstance(val_range, (list, tuple)) and len(val_range) >= 2:
                    config_params['val_end'] = val_range[1]
                    print(f"   âœ… æ‰¾åˆ° val_time_range: {val_range} â†’ val_end: {val_range[1]}")
            
            # test_end ä» test_time_range æå–ç»“æŸæ—¶é—´
            if hasattr(config_instance, 'test_time_range'):
                test_range = config_instance.test_time_range
                if isinstance(test_range, (list, tuple)) and len(test_range) >= 2:
                    config_params['test_end'] = test_range[1]
                    print(f"   âœ… æ‰¾åˆ° test_time_range: {test_range} â†’ test_end: {test_range[1]}")
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é…ç½®ç±»å®ä¾‹ï¼Œå°è¯•ä»æ¨¡å—çº§åˆ«å˜é‡ä¸­æå–
            print("ğŸ” æœªæ‰¾åˆ°é…ç½®ç±»å®ä¾‹ï¼Œå°è¯•ä»æ¨¡å—å˜é‡ä¸­æå–...")
            
            # è·å– dataset_path (å¯¹åº” output_dir)
            if hasattr(config_module, 'dataset_path'):
                config_params['output_dir'] = config_module.dataset_path
                print(f"   âœ… æ‰¾åˆ° dataset_path: {config_module.dataset_path}")
            
            # è·å–æ—¶é—´èŒƒå›´å‚æ•°
            if hasattr(config_module, 'train_time_range'):
                train_range = config_module.train_time_range
                if isinstance(train_range, (list, tuple)) and len(train_range) >= 2:
                    config_params['train_end'] = train_range[1]
                    print(f"   âœ… æ‰¾åˆ° train_time_range: {train_range} â†’ train_end: {train_range[1]}")
            
            if hasattr(config_module, 'val_time_range'):
                val_range = config_module.val_time_range
                if isinstance(val_range, (list, tuple)) and len(val_range) >= 2:
                    config_params['val_end'] = val_range[1]
                    print(f"   âœ… æ‰¾åˆ° val_time_range: {val_range} â†’ val_end: {val_range[1]}")
            
            if hasattr(config_module, 'test_time_range'):
                test_range = config_module.test_time_range
                if isinstance(test_range, (list, tuple)) and len(test_range) >= 2:
                    config_params['test_end'] = test_range[1]
                    print(f"   âœ… æ‰¾åˆ° test_time_range: {test_range} â†’ test_end: {test_range[1]}")
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸæå–åˆ°ä»»ä½•å‚æ•°
        if not config_params:
            print("âš ï¸  è­¦å‘Š: æœªä»é…ç½®æ–‡ä»¶ä¸­æå–åˆ°ä»»ä½•å‚æ•°")
            # æ‰“å°å¯ç”¨çš„å±æ€§ä»¥ä¾›è°ƒè¯•
            print("ğŸ” é…ç½®æ–‡ä»¶ä¸­çš„å¯ç”¨å±æ€§:")
            for attr_name in dir(config_module):
                if not attr_name.startswith('_'):
                    attr_value = getattr(config_module, attr_name)
                    if not callable(attr_value):  # åªæ˜¾ç¤ºéå‡½æ•°å±æ€§
                        print(f"   {attr_name}: {type(attr_value).__name__} = {attr_value}")
        else:
            print(f"\nâœ… ä»é…ç½®æ–‡ä»¶ {config_file_path} æˆåŠŸåŠ è½½ {len(config_params)} ä¸ªå‚æ•°")
        
        return config_params
        
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶ {config_file_path} å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return {}


def split_csv_to_pkl(
    csv_dir: str,
    output_dir: str,
    train_end: str,
    val_end: str,
    test_end: str = None,  # æ–°å¢ï¼šæµ‹è¯•é›†ç»“æŸæ—¥æœŸ
    date_col: str = "date",
    process_all: bool = False  # æ–°å¢ï¼šæ˜¯å¦å¤„ç†æ‰€æœ‰ CSVï¼Œé»˜è®¤ Falseï¼ˆä»…å¤„ç†ç¬¬ä¸€ä¸ªï¼‰
) -> None:
    """
    å°† CSV ç›®å½•ä¸‹çš„æ–‡ä»¶æŒ‰æ—¶é—´åˆ†å‰²ä¸º train/val/test .pkl
    é»˜è®¤ä»…å¤„ç†ç¬¬ä¸€ä¸ª CSV æ–‡ä»¶ï¼Œå¯é€šè¿‡ process_all=True å¤„ç†æ‰€æœ‰
    """
    # æ ¡éªŒæ—¥æœŸæ ¼å¼
    try:
        train_end_dt = datetime.strptime(train_end, "%Y-%m-%d")
        val_end_dt = datetime.strptime(val_end, "%Y-%m-%d")
        
        # å¦‚æœæä¾›äº† test_endï¼Œåˆ™ä½¿ç”¨å®ƒï¼Œå¦åˆ™ä½¿ç”¨ val_end ä¹‹åçš„æ‰€æœ‰æ•°æ®
        if test_end:
            test_end_dt = datetime.strptime(test_end, "%Y-%m-%d")
            if val_end_dt >= test_end_dt:
                raise ValueError("val_end å¿…é¡»æ—©äº test_end")
        else:
            test_end_dt = None
            
        if train_end_dt >= val_end_dt:
            raise ValueError("train_end å¿…é¡»æ—©äº val_end")
    except ValueError as e:
        raise ValueError(f"æ—¥æœŸæ ¼å¼é”™è¯¯ï¼ˆéœ€ä¸º YYYY-MM-DDï¼‰ï¼š{e}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    train_path = os.path.join(output_dir, "train_data.pkl")
    val_path = os.path.join(output_dir, "val_data.pkl")
    test_path = os.path.join(output_dir, "test_data.pkl")

    # åˆå§‹åŒ–ä¸‰ä¸ªæ•°æ®é›†ï¼ˆå­—å…¸ï¼škey=è‚¡ç¥¨ä»£ç ï¼Œvalue=DataFrameï¼‰
    train_data = {}
    val_data = {}
    test_data = {}

    # è·å–æ‰€æœ‰ CSV æ–‡ä»¶å¹¶æ’åºï¼ˆç¡®ä¿ç¬¬ä¸€ä¸ªæ–‡ä»¶å›ºå®šï¼‰
    csv_files = sorted([f for f in os.listdir(csv_dir) if f.endswith(".csv")])
    if not csv_files:
        raise FileNotFoundError(f"ç›®å½• {csv_dir} ä¸­æœªæ‰¾åˆ° CSV æ–‡ä»¶")

    # å†³å®šå¤„ç†çš„æ–‡ä»¶ï¼šé»˜è®¤ç¬¬ä¸€ä¸ªï¼Œprocess_all=True åˆ™å¤„ç†æ‰€æœ‰
    target_files = csv_files if process_all else [csv_files[0]]
    print(f"\nğŸ“ æ–‡ä»¶å¤„ç†ä¿¡æ¯:")
    print(f"   å‘ç°CSVæ–‡ä»¶æ•°é‡: {len(csv_files)}")
    print(f"   å¤„ç†æ¨¡å¼: {'å¤„ç†æ‰€æœ‰CSVæ–‡ä»¶' if process_all else 'ä»…å¤„ç†ç¬¬ä¸€ä¸ªCSVæ–‡ä»¶'}")
    print(f"   å®é™…å¤„ç†æ–‡ä»¶æ•°é‡: {len(target_files)}")
    if not process_all and len(csv_files) > 1:
        print(f"   ğŸ“ æç¤º: ä½¿ç”¨ --process-all å‚æ•°å¯å¤„ç†æ‰€æœ‰ {len(csv_files)} ä¸ªæ–‡ä»¶")
    print("-"*60)

    for idx, csv_file in enumerate(target_files, 1):
        csv_path = os.path.join(csv_dir, csv_file)
        instrument = os.path.splitext(csv_file)[0]  # è‚¡ç¥¨ä»£ç ï¼ˆæ–‡ä»¶åï¼‰

        try:
            # è¯»å– CSVï¼ˆæ ¹æ®æ˜¯å¦æœ‰æ—¥æœŸè¡¨å¤´å¤„ç†ç´¢å¼•ï¼‰
            if date_col:
                df = pd.read_csv(csv_path, parse_dates=[date_col], index_col=date_col)
            else:
                df = pd.read_csv(csv_path, parse_dates=True, index_col=0)

            # ç¡®ä¿ç´¢å¼•æ˜¯ datetime ç±»å‹
            if not pd.api.types.is_datetime64_any_dtype(df.index):
                raise TypeError(f"{instrument} çš„ç´¢å¼•ä¸æ˜¯æ—¶é—´ç±»å‹ï¼Œè¯·æ£€æŸ¥ CSV æ ¼å¼")

            # æŒ‰æ—¶é—´åˆ†å‰²æ•°æ®
            train_df = df[df.index <= train_end_dt]
            val_df = df[(df.index > train_end_dt) & (df.index <= val_end_dt)]
            
            # æ ¹æ®æ˜¯å¦æä¾› test_end åˆ†å‰²æµ‹è¯•é›†
            if test_end:
                test_df = df[(df.index > val_end_dt) & (df.index <= test_end_dt)]
            else:
                test_df = df[df.index > val_end_dt]

            # è¿‡æ»¤ç©ºæ•°æ®é›†
            if not train_df.empty:
                train_data[instrument] = train_df
            if not val_df.empty:
                val_data[instrument] = val_df
            if not test_df.empty:
                test_data[instrument] = test_df

            print(f"[{idx}/{len(target_files)}] å¤„ç†å®Œæˆï¼š{instrument} "
                  f"(train: {len(train_df)}, val: {len(val_df)}, test: {len(test_df)})")

        except Exception as e:
            print(f"å¤„ç† {csv_file} å¤±è´¥ï¼š{str(e)}")

    # ä¿å­˜ä¸º .pkl æ–‡ä»¶
    with open(train_path, "wb") as f:
        pickle.dump(train_data, f)
    with open(val_path, "wb") as f:
        pickle.dump(val_data, f)
    with open(test_path, "wb") as f:
        pickle.dump(test_data, f)

    print(f"\n" + "="*60)
    print("âœ… æ•°æ®å¤„ç†å®Œæˆ")
    print("="*60)
    
    print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    if test_end:
        print(f"   ğŸŸ¢ è®­ç»ƒé›†ï¼ˆâ‰¤ {train_end}ï¼‰: {len(train_data)} åªè‚¡ç¥¨")
        print(f"   ğŸŸ¡ éªŒè¯é›†ï¼ˆ{train_end} < x â‰¤ {val_end}ï¼‰: {len(val_data)} åªè‚¡ç¥¨")
        print(f"   ğŸ”´ æµ‹è¯•é›†ï¼ˆ{val_end} < x â‰¤ {test_end}ï¼‰: {len(test_data)} åªè‚¡ç¥¨")
    else:
        print(f"   ğŸŸ¢ è®­ç»ƒé›†ï¼ˆâ‰¤ {train_end}ï¼‰: {len(train_data)} åªè‚¡ç¥¨")
        print(f"   ğŸŸ¡ éªŒè¯é›†ï¼ˆ{train_end} < x â‰¤ {val_end}ï¼‰: {len(val_data)} åªè‚¡ç¥¨")
        print(f"   ğŸ”´ æµ‹è¯•é›†ï¼ˆ> {val_end}ï¼‰: {len(test_data)} åªè‚¡ç¥¨")
    
    print(f"\nğŸ’¾ æ–‡ä»¶ä¿å­˜ä½ç½®:")
    print(f"   è®­ç»ƒé›†: {train_path}")
    print(f"   éªŒè¯é›†: {val_path}")
    print(f"   æµ‹è¯•é›†: {test_path}")
    
    print(f"\nğŸ¯ å¤„ç†ç»“æœ:")
    total_stocks = len(train_data) + len(val_data) + len(test_data)
    print(f"   æˆåŠŸå¤„ç†è‚¡ç¥¨æ€»æ•°: {total_stocks}")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    
    print("="*60)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="CSV æŒ‰æ—¶é—´åˆ†å‰²ä¸º train/val/test .pklï¼ˆé»˜è®¤å¤„ç†ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼‰")
    parser.add_argument("--csv-dir", type=str, required=True,
                        help="CSV æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆå¦‚ ./qlib_merged_csvï¼‰")
    parser.add_argument("--output-dir", type=str, default="./split_pkl",
                        help="è¾“å‡º train/val/test .pkl çš„ç›®å½•")
    parser.add_argument("--train-end", type=str, required=True,
                        help="è®­ç»ƒé›†ç»“æŸæ—¥æœŸï¼ˆå¦‚ 2018-12-31ï¼‰")
    parser.add_argument("--val-end", type=str, required=True,
                        help="éªŒè¯é›†ç»“æŸæ—¥æœŸï¼ˆå¦‚ 2020-12-31ï¼‰")
    parser.add_argument("--test-end", type=str, default=None,
                        help="æµ‹è¯•é›†ç»“æŸæ—¥æœŸï¼ˆå¦‚ 2022-12-31ï¼‰ï¼Œå¯é€‰")
    parser.add_argument("--date-col", type=str, default="date",
                        help="CSV ä¸­æ—¶é—´åˆ—çš„è¡¨å¤´ï¼ˆè‹¥æœªæŒ‡å®šè¡¨å¤´åˆ™è®¾ä¸º ''ï¼‰")
    parser.add_argument("--process-all", action="store_true",
                        help="æ·»åŠ æ­¤å‚æ•°åˆ™å¤„ç†æ‰€æœ‰ CSV æ–‡ä»¶ï¼ˆé»˜è®¤ä»…å¤„ç†ç¬¬ä¸€ä¸ªï¼‰")
    parser.add_argument("--config-file", type=str, default="/root/Kronos/finetune/config.py",
                        help="é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºè¯»å–å‚æ•°ï¼ˆé»˜è®¤: /root/Kronos/finetune/config.pyï¼‰")
    args = parser.parse_args()

    # å¦‚æœæä¾›äº†é…ç½®æ–‡ä»¶ï¼Œåˆ™ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–å‚æ•°
    config_params = {}
    if args.config_file and os.path.exists(args.config_file):
        config_params = load_config(args.config_file)
    
    # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°è¦†ç›–å‘½ä»¤è¡Œå‚æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    output_dir = config_params.get('output_dir', args.output_dir)
    train_end = config_params.get('train_end', args.train_end)
    val_end = config_params.get('val_end', args.val_end)
    test_end = config_params.get('test_end', args.test_end)
    
    # éªŒè¯å¿…éœ€å‚æ•°
    if not train_end:
        raise ValueError("train_end å‚æ•°æœªæä¾›ï¼Œè¯·é€šè¿‡å‘½ä»¤è¡Œæˆ–é…ç½®æ–‡ä»¶è®¾ç½®")
    if not val_end:
        raise ValueError("val_end å‚æ•°æœªæä¾›ï¼Œè¯·é€šè¿‡å‘½ä»¤è¡Œæˆ–é…ç½®æ–‡ä»¶è®¾ç½®")

    print("\n" + "="*60)
    print("ç¨‹åºæ‰§è¡Œå‚æ•°æ±‡æ€»")
    print("="*60)
    
    # æ˜¾ç¤ºå‚æ•°æ¥æº
    if config_params:
        print("ğŸ“ å‚æ•°æ¥æº: é…ç½®æ–‡ä»¶ + å‘½ä»¤è¡Œå‚æ•° (é…ç½®æ–‡ä»¶ä¼˜å…ˆ)")
        print(f"   é…ç½®æ–‡ä»¶è·¯å¾„: {args.config_file}")
    else:
        print("ğŸ“ å‚æ•°æ¥æº: å‘½ä»¤è¡Œå‚æ•°")
    
    print("\nğŸ“Š æ•°æ®å¤„ç†å‚æ•°:")
    print(f"   CSVç›®å½•: {args.csv_dir}")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    print(f"   æ—¥æœŸå­—æ®µ: {args.date_col}")
    print(f"   å¤„ç†æ¨¡å¼: {'æ‰€æœ‰CSVæ–‡ä»¶' if args.process_all else 'ä»…ç¬¬ä¸€ä¸ªCSVæ–‡ä»¶'}")
    
    print("\nğŸ“… æ—¶é—´èŒƒå›´å‚æ•°:")
    print(f"   è®­ç»ƒé›†ç»“æŸ: {train_end}")
    print(f"   éªŒè¯é›†ç»“æŸ: {val_end}")
    if test_end:
        print(f"   æµ‹è¯•é›†ç»“æŸ: {test_end}")
        print(f"   æ—¶é—´èŒƒå›´: {train_end} â†’ {val_end} â†’ {test_end}")
    else:
        print(f"   æµ‹è¯•é›†ç»“æŸ: è‡ªåŠ¨ä½¿ç”¨ {val_end} ä¹‹åçš„æ‰€æœ‰æ•°æ®")
        print(f"   æ—¶é—´èŒƒå›´: {train_end} â†’ {val_end} â†’ æ•°æ®ç»“æŸ")
    
    print("\nğŸ” å‚æ•°è¯¦æƒ…:")
    print(f"   csv_dir: {args.csv_dir}")
    print(f"   output_dir: {output_dir}")
    print(f"   train_end: {train_end}")
    print(f"   val_end: {val_end}")
    print(f"   test_end: {test_end}")
    print(f"   date_col: {args.date_col}")
    print(f"   process_all: {args.process_all}")
    print(f"   config_file: {args.config_file}")
    
    print("="*60)
    print("å¼€å§‹å¤„ç†æ•°æ®...")
    print("-"*60)

    split_csv_to_pkl(
        csv_dir=args.csv_dir,
        output_dir=output_dir,
        train_end=train_end,
        val_end=val_end,
        test_end=test_end,
        date_col=args.date_col,
        process_all=args.process_all
    )